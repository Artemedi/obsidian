### Методы измерения производительности запросов  

Для того чтобы понять, на каких запросах следует сосредоточиться при их настройке, нам необходим метод точного измерения производительности запросов. Кроме того, по мере того как мы будем предпринимать различные попытки улучшить производительность запросов, нам необходимо уметь фиксировать метрики, которые позволят нам понять, насколько хорошо работают наши улучшения и работают ли они вообще. И, наконец, нам нужно уметь измерять результаты наших улучшений, чтобы подтвердить их эффективность и начать процесс заново, выявляя следующий плохо работающий запрос. Несмотря на то, что существует большое количество механизмов для определения производительности запросов, мы сосредоточим наши усилия на трех, которые, по моему мнению, являются наиболее точными и простыми в реализации.  
Хотя остальные механизмы тоже работают, я считаю, что эти три работают лучше всего. Если вы решите использовать другой механизм, просто будьте последовательны в том, что вы измеряете, потому что каждый инструмент сбора метрик, который я использовал, отличается от всех остальных.  
В этой главе мы узнаем о следующем  
  
- Использование динамических представлений управления  
- Сбор подробных метрик с помощью расширенных событий  
- Метрики производительности запросов в хранилище запросов  
#queryperformance

## Методы сбора метрик производительности запросов  
  
Существует большое количество способов сбора метрик запросов. Большинство из них одинаково точны, но некоторые либо проще в использовании, либо дают более полную информацию, либо лучше работают в масштабе больших систем. Позвольте мне пробежаться по всем возможным вариантам, а затем мы кратко обсудим, почему я не использую одни показатели так же часто, как другие. Ниже перечислены возможные методы измерения производительности запросов:  
  
- Включение статистики клиента  
- Свойства соединения  
- SET STATISTICS TIME/IO  
- QueryTimeStats в плане выполнения  
- Хранилище запросов  
- Представления динамического управления (DMVs)  
- События трассировки (Profiler)  
- Расширенные события  
  
Поскольку о DMVs, Query Store и Extended Events мы будем говорить в оставшейся части главы, я хочу рассказать об остальном прямо здесь. Начнем с единственного показателя, который на самом деле не является точным (в отличие от всех остальных), - Include Client Statistics.  
  
## Включить статистику клиентов 

Для этого нужно щелкнуть правой кнопкой мыши в окне запроса в SQL Server Management Studio (SSMS) и выбрать из контекстного меню пункт "Include Client Statistics". При этом будет фиксироваться время выполнения и ввод-вывод с клиента, на котором выполняется запрос. Это означает, что сетевое время, локальная борьба за ресурсы и все остальное негативно скажется на измерении производительности. Вывод этих значений никак не совпадает с результатами других методов. В связи с этим я просто никогда не использую этот метод.  
#ClientStatistics

## Свойства соединения  
  
Этот метод на самом деле очень удобен, хотя я не использую его в качестве основной меры. Перед выполнением запроса или даже после него щелкните правой кнопкой мыши в окне запроса в SSMS и выберите в контекстном меню пункт "Свойства". В результате откроется окно Properties (которое мы будем часто использовать с планами выполнения на протяжении всей книги; я обычно оставляю это окно открытым и доступным все время работы). В нем вы найдете информацию "Детали соединения". Эта информация включает в себя "Время, прошедшее с момента подключения", которое на самом деле является точным показателем производительности запроса. Хотя в SSMS производительность запроса можно увидеть в нижней части экрана, она измеряется только с точностью до секунды.  
Здесь же значения точны до миллисекунд. Единственная проблема заключается в том, что он не дает нам измерения ввода/вывода, поэтому он не так полезен, как другие измерения, которые дают нам и прошедшее время, и ввод/вывод, и, в некоторых случаях, использование процессора. Однако если вы забудете включить какой-либо другой механизм сбора данных, то этот всегда будет доступен, что, опять же, делает его очень удобным.
#ConnectionProperties
  
## SET STATISTICS TIME/IO  
  
Это классический механизм измерения производительности при настройке запросов. В предыдущих версиях книги эти значения широко использовались. Они точны, поэтому если вы решите их использовать, то все будет в порядке. Их можно использовать, зайдя в Options для SSMS, щелкнув правой кнопкой мыши и выбрав их из контекстного меню, или используя T-SQL для SET STATISTICS TIME ON (что делает этот механизм удобным и в Azure Data Studio).  
Позвольте мне объяснить, почему я больше не использую их. Во-первых, вы получаете только одно измерение. Я обнаружил, что получаю более точные результаты, если выполняю запрос несколько раз, а затем усредняю результаты. Это очень трудно сделать с помощью данного измерения. Вы также не получаете данных об использовании процессора. Наконец, если вы фиксируете TIME и IO с помощью этого метода, то фиксация IO может негативно повлиять на фиксацию TIME, сделав ее менее точной. Обычно это заметно только для запросов, выполняющихся менее секунды или даже менее 100 миллисекунд. Тем не менее, когда точность нужна больше всего, приходится настраиваться на последние несколько миллисекунд. Отсутствие такой точности снижает полезность этого механизма.  
#SETSTATISTICS

## QueryTimeStats в Плане выполнения  
  
При захвате метрик времени выполнения с планом выполнения, который в SSMS, начиная с 2016 года, называется "Фактический план выполнения", вы получаете метрики времени выполнения запроса, включая статистику ожидания. Это точные измерения, которые являются частью плана выполнения. Я обязательно буду их использовать. Однако, опять же, они отображаются только для одного выполнения, что затрудняет получение средних значений. Кроме того, захват планов выполнения негативно сказывается на измерении времени, поскольку захват метрик времени выполнения вместе с планом выполнения замедляет выполнение запроса. По этой причине, когда мне нужны точные показатели производительности, я не беру планы выполнения. Этот простой факт означает, что я не могу полагаться на этот показатель постоянно.  
  
## Трассировка событий (Profiler)  
  
Это может быть болезненной темой. Многие опытные специалисты по работе с данными уже давно работают с Trace Events и Profiler (графический интерфейс пользователя для работы с данными Trace Event). Использование этих инструментов для них комфортно, они приобрели отличные навыки работы с ними и не собираются останавливаться. Я не собираюсь стоять у них на пути. Однако по ряду причин я не буду пропагандировать использование Trace Events, и если вы только начинаете заниматься настройкой производительности запросов, я настоятельно рекомендую не использовать их.  
Во-первых, Trace Events очень дорогостоящая операция для операционной системы SQL Server. В отличие от Extended Events, которые, начиная с SQL Server 2008, были включены непосредственно во внутреннюю модель SQL Server, Trace Events были разработаны и внедрены отдельно. Это приводит к тому, что они занимают больше памяти и процессора, чем Extended Events. 
Из-за того, что Trace Events собирают информацию, их нельзя отфильтровать на этапе захвата, как в случае Extended Events. Это означает, что все необходимые для захвата события ресурсы используются, а затем происходит фильтрация и это событие удаляется из результатов.
Другая проблема связана с графическим интерфейсом Profiler. Если подключить Profiler GUI к Trace Events на рабочем сервере, то он создает на нем дополнительное пространство памяти и использует его для обработки событий в реальном времени, что приводит к сокращению ресурсов системы.
Наконец, использование данных в Trace Events не так эффективно, как это можно сделать с помощью окна Live Data Explorer в Extended Events.
По всем этим причинам на системах с SQL Server 2012 и выше я не буду использовать Trace Events для сбора информации. До 2012 года Trace Events по-прежнему является предпочтительным механизмом.
#profiler

## Представления динамического управления  

Существует очень большое количество DMV. Даже если мы ограничимся рассмотрением DMV, связанных с производительностью запросов, их все равно будет очень много. Поэтому я не буду пытаться описать их все и способы их использования. Вместо этого мы рассмотрим здесь основные DMV, связанные с производительностью запросов, а о дополнительных DMV мы будем говорить на протяжении всей книги (некоторые из них мы представили в главе 2).  
DMV делятся на две большие категории: для запросов, выполняющихся в данный момент, и для запросов, которые были выполнены ранее. Информация, собранная для ранее выполненных запросов, полностью зависит от кэша. Если по какой-либо причине запрос устарел или был принудительно удален из кэша, то все метрики запроса уходят вместе с ним. Кроме того, информация о ранее выполненных запросах является только агрегированной. Вы не сможете отличить запрос, выполненный в 2 часа ночи, от того же запроса, выполненного в 3 часа ночи, если только не воспользуетесь DMV для сбора метрик в оба времени.  
обоих случаях.  
Я часто использую DMV для метрик запросов по нескольким причинам. Во-первых, большинство из них доступны во всех версиях SQL Server, начиная с 2005 года и выше, включая AWS RDS и Azure SQL Database. Это означает, что у меня всегда есть возможность получить метрики производительности запросов. Во-вторых, не всегда на сервере будут постоянно включены другие методы. Некоторые базы данных могут иметь слишком высокую нагрузку для работы Query Store. Хотя Extended Events очень легки, они не бесплатны, поэтому они тоже не будут запущены всегда.  
Тем не менее, я всегда смогу взглянуть на метрики запросов через DMV.  
Давайте сначала рассмотрим, как можно перехватывать активно выполняющиеся запросы. 
#dvm

## Запросы с активным выполнением

Важно воспринимать DMV как строительные блоки или лего. Их можно собирать по-разному. Однако есть несколько отправных точек, к которым вы всегда будете возвращаться. Для запросов, которые находятся в активном выполнении, отправной точкой чаще всего является sys.dm_exec_requests. Этот DMV собирает огромное количество информации об исполняющихся запросах, включая следующие сведения:  
  
- Starttime: Когда запрос начал выполняться  
- Command Type: Какой это тип запроса  
- Plan_handle: Используется для получения плана выполнения из кэша  
- Sql_handle: Используется для получения текста T-SQL из кэша  
- Blocking_session_id: Если процесс заблокирован, то какая сессия его блокирует  
- Wait_type: Если процесс ожидает, то чего он ожидает  
- Total_elapsed_time: Сколько времени выполняется процесс  
- Cpu_time: Сколько процессора было потреблено процессом  
- Reads: Сколько чтений было выполнено этим процессом  
- Writes: Сколько записей было произведено этим процессом.  
  
Существует еще больше полезной информации, но общее представление вы получили.  
Чтобы действительно использовать DMV для получения интересной информации, нам потребуется объединить его с несколькими другими DMV. Первая - sys.dm_exec_query_plan(), которая содержит все планы выполнения, находящиеся в кэше планов. Вторая - sys.dm_exec_sql_text(), которая содержит пакетный текст T-SQL для выполняемого запроса. В листинге 3-1 показан один из возможных способов комбинирования этих DMV для получения полезных метрик запроса для выполняющихся в данный момент запросов.  
  
Листинг 3-1. Комбинирование sys.dm_exec_requests с другими DMV
```sql
SELECT  dest.text,
		deqp.query_plan,
		der.cpu_time,
		der.logical_reads,
		der.writes
FROM sys.dm_exec_requests AS der
	CROSS APPLY sys.dm_exec_query_plan(der.plan_handle) AS deqp
	CROSS APPLY sys.dm_exec_sql_text(der.plan_handle) AS dest;
```

Вы можете использовать гораздо более сложные запросы к этим DMV, например возвращать отдельные данные, а не целые пакеты, отфильтровывать session_id для самого запроса и многое другое. Однако этого вполне достаточно для начала работы.

## Выполненные ранее запросы  
  
Для просмотра ранее выполненных запросов у нас есть несколько вариантов с чего начать. Наиболее распространенным является использование sys.dm_exec_query_stats. Этот DMV содержит много интересной информации, когда речь идет о метриках производительности запросов:  
  
- Sql_handle: Используется для получения T-SQL для пакета.  
- Plan_handle: Используется для получения плана выполнения запроса  
- Last_execution_time: Время последнего выполнения данного запроса  
- Execution_count: Сколько раз был выполнен запрос  
- Total_logical_reads: Количество логических чтений  
- Last_logical_reads: Количество чтений при последнем выполнении запроса  
- Avg_logical_reads: Среднее число чтений за все запуски запроса.  
  
И, как и прежде, многое другое. Вы можете увидеть общее, среднее, минимальное и максимальное значение по по целому ряду показателей, включая время, процессор, чтение и запись.  
Как и раньше, вы можете комбинировать этот показатель с другими DMV, чтобы получить более полную картину. полную картину. В листинге 3-2 показан один из возможных способов просмотра данных.  
  
Листинг 3-2. Комбинирование sys.dm_exec_query_stats с другими DMV

```sql
SELECT 
	dest.text,
	deqp.query_plan,
	deqs.execution_count,
	deqs.min_logical_writes,
	deqs.max_logical_reads,
	deqs.total_logical_reads,
	deqs.total_elapsed_time,
	deqs.last_elapsed_time
FROM sys.dm_exec_query_stats AS deqs
	CROSS APPLY sys.dm_exec_query_plan(deqs.plan_handle) AS deqp
	CROSS APPLY sys.dm_exec_sql_text(deqs.sql_handle) AS dest;
```

Можно добавить предложение WHERE для поиска определенного текста и многое другое. Существуют также специальные DMV для определенных типов объектов:

- sys.dm_exec_procedure_stats: Работает аналогично sys.dm_exec_query_stats, но только для хранимых процедур  
- sys.dm_exec_function_stats: Та же идея, но для функций, определяемых пользователем  
- sys.dm_exec_trigger_stats: Возвращает агрегированную информацию о производительности триггера  
  
С помощью всех этих DMV можно получить информацию, необходимую для отображения агрегированной производительности запросов, находящихся в кэше. Мы покажем дополнительные примеры запросов с использованием DMV на протяжении всей книги.  

## Query Store

Query Store был представлен в SQL Server 2016 и с тех пор претерпел ряд обновлений в каждом выпуске. Основное поведение не изменилось. Query Store включается для каждой базы данных отдельно. Оно будет собирать метрики запросов в агрегированном виде и хранить их в базе данных, где оно включено. Агрегированные показатели разбиваются по времени; по умолчанию это 60 минут, что позволяет сравнивать производительность во времени, а не просто опираться на агрегированные показатели. Мы подробно рассмотрим Query Store  
в главе 6, поскольку там очень много информации. Тем не менее, я хотел бы затронуть эту тему здесь как один из трех основных методов сбора метрик запросов.  
  
## Extended Events

Впервые расширенные события были представлены в SQL Server 2008, однако в то время они просто не обеспечивали достаточного уровня функциональности, чтобы сделать их полезными для сбора метрик запросов. Однако обновления Extended Events, представленные в SQL Server 2012, включающие графический интерфейс, а также ряд изменений в их поведении и множество новых событий, сделали их не только пригодными для сбора метрик запросов, но и наиболее эффективным способом получения подробной информации о производительности запросов. Trace Events и Profiler по-прежнему работают в SQL Server, но не в Azure SQL Database. Однако, учитывая затраты, которые они вносят в систему, и отсутствие современной функциональности, я не буду использовать их в книге и не рекомендую применять их в системах, работающих под управлением SQL Server 2012 и выше.  

Расширенные события состоят из множества различных программируемых конструкций, однако мы собираемся максимально упростить их использование. В связи с этим мы сосредоточимся на следующем:

- Sessions (Сессии) : Определяют, какие события будут фиксироваться, как они будут храниться, как они будут связаны друг с другом, и все другие аспекты поведения Extended Events.  
- Events (События) : Действия, происходящие в SQL Server, одним из основных направлений которых является производительность запросов, но также включает такие вещи такие как ожидание, перекомпиляция, тупики и т.д.  
- Global Fields ( Actions ): Это дополнительные элементы информации которые могут быть добавлены к определенному событию. Они представляют собой дополнительные функциональную активность в SQL Server, поэтому должны использоваться с умом.  
- Event Fields (Поле событий): Каждое событие состоит из комбинации стандартной и дополнительной информации, которая должна быть записана. Это ключевые данные, которые делают Extended Events очень полезными.  
- Predicates (Предикаты): Проще говоря, это предложение WHERE, которое может быть добавлено к расширенным событиям для фильтрации полученной информации.  
- Targets (Цели): Здесь определяется, где хранятся перехваченные данные. По умолчанию здесь используется Ring Buffers, область памяти в Windows, но в производственной среде это не должно использоваться.  
  
Расширенные события можно создавать, редактировать, запускать, останавливать и удалять с помощью GUI-интерфейса в SQL Server Management Studio, более ограниченного интерфейса в Azure Data Studio или с помощью T-SQL. Большую часть времени в этой главе мы посвятим рассмотрению графического интерфейса, поскольку это самый простой способ начать работу с расширенными событиями. В SSMS даже появился графический интерфейс под названием XEvent Profiler, который эмулирует два наиболее распространенных шаблона из Profiler для сбора информации о запросах. Это быстрый способ сразу же увидеть метрики запросов с помощью Extended Events. Однако в данной книге мы не будем его рассматривать. Мы сосредоточимся на том, чтобы показать вам, как создавать свои собственные пользовательские сеансы. Наконец, существует еще один графический интерфейс, называемый окном Live Data, который позволяет исследовать информацию, полученную с помощью Extended Events.  
#ExtendedEvents

## Создание сеанса расширенных событий  
  
Для создания пользовательского сеанса расширенных событий в SSMS существует два отдельных графических интерфейса: мастер создания нового сеанса и окно нового сеанса. Мастер практически ничего не добавляет к процессу и может скрывать некоторые функциональные возможности, поэтому мы сосредоточимся только на окне New Session. Кроме того, окно New Session так же просто в использовании, как и мастер. Вы также будете использовать окно New Session, когда захотите отредактировать сессию, поэтому нелишним будет ознакомиться с ним поближе.
Чтобы получить доступ к окну New Session, необходимо перейти в Object Explorer. Откройте меню Management, затем Extended Events и, наконец, Sessions, как показано на рис. 3-1. 

![[Figure 3-1.png]]

Рисунок 3-1. Object Explorer, показывающий, где расположены сессии расширенных событий

Если затем щелкнуть правой кнопкой мыши на Sessions, то появится контекстное меню. Выберите пункт "New Session..." и откроется окно New Session, как показано на рис. 3-2.

![[Figure 3-2.png]]

Рисунок 3-2. Окно "Новый сеанс"

Единственное, что здесь нужно заполнить, - это "Session name". Остальные параметры здесь необязательны. Имя сессии может содержать пробелы. Максимальное количество символов - 128, а имя сессии должно быть уникально на сервере. Я стараюсь использовать достаточно подробные имена, чтобы было понятно, какого рода мониторинг выполняет сессия. 
У вас есть выбор - пойти дальше и создать пользовательский сеанс, или воспользоваться шаблонами. Это выпадающее меню с большим выбором различных шаблонов, большинство из которых ориентированы на сбор показателей производительности различными способами. Также есть возможность загрузить сессию из файла. В качестве примера можно привести следующие шаблоны:

- Count Query Locks: Шаблон, использующий целевую гистограмму вместе с хэш-значением запроса для подсчета блокировок в каждом запросе.
- TSQL: Один из шаблонов "Profiler Equivalent". Он фиксирует входы в систему, а также пакетное выполнение и завершение удаленного вызова процедур (RPC). 
- Query Batch Sampling: Шаблон, специфичный для Extended Events, который использует фильтр для захвата метрик запросов только для 20% всех сессий, работающих на сервере.
- Query Detail Tracking: Захватывает всевозможные типы завершения запросов, пакетных запросов и RPC, отфильтровывая при этом системные запросы и системные базы данных.
- Query Wait Statistic (Статистика ожидания запроса): Еще один шаблон, доступный только для Extended Events, в котором фиксируется каждый запуск и завершение запроса, а также все операторы, внутреннее и внешнее ожидание в 20% всех сессий, включая Causality Tracking (подробно описано далее в этой главе). 

Другими словами, у вас есть с чем работать, а можете продолжить и создать свои собственные сеансы и события.
В центре окна, показанного на рис. 3-2, вы можете увидеть некоторые опции доступные для вашей сессии. Вы можете включить или отключить запуск сессии при старте сервера. Также можно немедленно запустить сессию после завершения ее редактирования. Помимо этого, можно сразу же открыть окно Live Data для просмотра результатов сессии. Я часто пользуюсь этой функцией, особенно при первой настройке сессии. В нижней части экрана можно включить или отключить Causality Tracking для сессии. 
После этого можно нажать на левую часть экрана, где написано Events (События), чтобы начать добавлять и настраивать события.

## Добавление и настройка событий

В любой сессии должно быть добавлено хотя бы одно событие. В любой сессии может быть любое количество событий. Однако я рекомендую проявлять осторожность при добавлении событий в сессию. поскольку перегрузка системы событиями может оказать серьезное негативное воздействие на нее. 
Когда вы впервые открываете страницу Events, она должна выглядеть примерно так, как показано на рис. 3-3.

![[Figure 3-3.png]]

Рисунок 3-3. Выбор сеанса для Extended Events

Окно можно максимизировать, чтобы развернуть столбцы и сделать их более удобными для чтения. Оставлю все по умолчанию, чтобы вы увидели примерно то же самое, что вижу я.  
Список событий находится прямо перед вами. По умолчанию в списке отображаются все события, однако прямо на экране у вас есть четыре различных способа отфильтровать события. В верхней части находится поисковое текстовое окно. Оно автоматически выполняет поиск по символам. Например, если я ищу событие rpc_completed, я могу ввести в окно слово "completed", и в результате у меня получится довольно длинный список. Я могу прокрутить его, чтобы найти то, что мне нужно, как показано на рис. 3-4.  

![[Figure 3-4.png]]

Рисунок 3-4. События, отфильтрованные только по слову "completed"

Можно также изменить способ поиска. По умолчанию, как показано в раскрывающемся списке, расположенном непосредственно рядом с текстовым полем, поиск ведется только по "Event names only". С помощью раскрывающегося списка можно выбрать и другие варианты:  
- Event names and descriptions (Названия и описания событий)
- Event fields only (Только поля события)
- All (Все)

В дополнение к текстовому полю поиска можно также фильтровать по категориям, каналам и пакетам. Я обычно оставляю эти параметры без внимания, поскольку могу найти то, что мне нужно, с помощью поисковой строки. Единственное исключение - канал. Существует только четыре канала:

- Admin (Администратор)
- Analytic (Аналитический)
- Debug (Отладка)
- Operational (Операционный)

По умолчанию канал Debug отключен. Это связано с тем, что события в канале Debug могут быть изменены компанией Microsoft без предварительного уведомления. Кроме того, некоторые события в канале Debug являются опасными. Я рекомендую быть крайне осторожным при использовании событий канала Debug. Лучше просто отказаться от использования этого канала. Определив интересующее меня событие, можно щелкнуть на нем, после чего окно изменится и будет выглядеть так, как показано на рис. 3-5.  

![[Figure 3-5.png]]

Рисунок 3-5. Клик на событии в разделе Extended Events

Теперь заполнены оба поля под Списком событий. Первое окно представляет собой описание выбранного в данный момент события. Второе окно представляет собой список связанных с событием и описанием этих Полей, включая метрические определения. Например, в описании поля duration указано, что значения в нем указаны в микросекундах. По умолчанию эти колонки узкие. Однако можно изменить их размер, чтобы было удобнее читать.  
После того как вы определили, что данное событие является тем, которое вы хотите добавить в сессию, нажмите на стрелку, указывающую вправо посередине окна. Это переместит событие из Library Event (Библиотека событий) слева в Selected events (Выбор событий) справа. На рис. 3-6 я выбрал два события и добавил их в список Selected events (Выбор событий).

![[Figure 3-6.png]]

Рисунок 3-6. Два события добавлены в список Selected events (Выбранные события)

Вот здесь мы сделали все, что нужно для создания сеанса Extended Events(Расширенные события). Мы присвоили сеансу имя и добавили одно или несколько событий. На данном этапе все настройки по умолчанию работают и мы можем создать сессию. Однако нам еще предстоит понять, как настроить события в сеансе, поэтому давайте нажмем кнопку Configure, которая появляется после добавления событий в сеанс. Эта кнопка видна в правом верхнем углу рис. 3-6.  
При нажатии на кнопку мы переходим в другое окно, показанное на рис. 3-7.  
  
![[Figure 3-7.png]]

Рисунок 3-7. Окно конфигурации события

Мы рассмотрим каждую из вкладок, которые вы видите на рисунке: " "Global Fields" (Глобальные поля)", "Filter" (Фильтр) и "Event Fields" (Поля событий).

## Добавление Global Fields(Глобальные поля) в Event(События).  
  
Первой вкладкой, открытой по умолчанию в окне конфигурации события, будет Global Fields (Глобальные поля). Их также называют Action (действия), что является более точным. Это дополнительные элементы данных, которые можно добавлять к Events(Событиям). Как видите, столбцы по умолчанию слишком узкие. Вы можете расширить их, чтобы лучше видеть, какие данные в них содержатся. Для каждого Action (Действия) также дается описание, в котором указывается, что будет создано или собрано в результате этого Action (Действия). 
В левой части экрана можно выделить одно или несколько Events (Событий).  
Можно нажать клавишу shift, чтобы выбрать все действия или клавишу control, чтобы выбрать конкретные действия. Хорошим примером действия, которое стоит добавить для тех метрик запросов, которые нас больше всего интересуют, являются значения query_hash и query_plan_hash. Их называют своеобразными отпечатками запросов. Более подробно мы рассмотрим их в последующих главах. Чтобы добавить данные к собираемым событиям, я выберу оба события. Прокрутив страницу вниз, в поле Actions (Действия), выделим их щелчком мыши. Теперь мое окно выглядит так, как показано на рис. 3-8.

![[Figure 3-8.png]]

Рисунок 3-8. Выбор Global Fields(Глобальные поля) для нескольких Events(Событий)

На рисунке 3-8 видно, что у меня выделены оба значения. Также видно, что Selected events (Выбранные события) слева изменился. Под символом молнии для каждого события отображается цифра 2. Это означает, что были добавлены два действия. Если для разных событий были выбраны разные действия, то эти цифры могут быть разными. Если ни одно действие не выбрано, то будет показано значение ноль (0), как это было на рис. 3-7.

## Использование Predicates(Предикаты) с Events(Событиями)  
  
На следующей вкладке мы определяем Filter(фильтр), или Predicate (предикат), для Events(события). Предикат функционирует так же, как и предложение WHERE в запросе. На самом деле, когда мы рассмотрим язык T-SQL далее в этой главе, вы увидите, что он является оператором WHERE, в буквальном смысле этого слова. При первом просмотре настроенного сеанса, как мы это делаем, экран будет пустым, как показано на рис. 3-9.

![[Figure 3-9.png]]

Рисунок 3-9. Вкладка Filter (Фильтр) или Predicate (Предикат) для настройки событий

Как и в случае с Actions (Действиями), вы можете выбирать события по отдельности или объединять их в группы для определения Predicates(Предикаты). Фактически работа с Predicates (Предикаты) проста. Как показано на рис. 3-9, щелкните мышью в том месте, где написано Click here to add a clause (Щелкните здесь, чтобы добавить условие). Сразу же появится новая строка, как показано на рис. 3-10.

![[Figure 3-10.png]]

Рисунок 3-10. Добавление Predicate(Предикат) к набору Events(События)

Далее следует щелкнуть на раскрывающемся окне с надписью Field (Поле). Откроется список значений. Он зависит от того, какое Event (Событие) или Events (События) вы выбрали слева. Если выбрано одно событие, то сначала будет показан список всех событий (Event Fields), а затем список всех действий (Actions). Вы можете фильтровать по любому из них. Если выбрано несколько Events (Событий), как в моем примере, то сначала отображается список общих Event Fields (Полей события), а затем Actions (Действий).
Extended Events (Расширенные события) фильтруют события на основе Predicate (Предикат), который вы указываете при захвате события. Это означает, что необходимо использовать наиболее строгие критерии фильтрации. Кроме того, необходимо убедиться, что более строгий фильтр применяется первым, чтобы снизить затраты на перехват событий. 
В моем примере я собираюсь выбрать Action (действие) для имени базы данных. Оно отображается как sqlserver.database_name. Это означает, что само действие является частью системы SQL Server, в отличие от действий ОС SQL Server, которые отображаются как sqlos.*. 
После выбора поля необходимо выбрать оператор. По умолчанию используется оператор равенства. Поэтому необходимо точное совпадение. Операторы включают, но не ограничиваются этим:

- Equals: Для точного совпадения
- Less Than (Меньше): Для определения значений, которые меньше другого
- Greater Than (Больше): Для нахождения значений, которые больше другого
- Like: Для поиска совпадений с паттерном

Существует большое количество других логических операторов для фильтрации событий. Это наиболее распространенные.
Наконец, необходимо указать значение, с которым будет сравниваться логический оператор. Это могут быть строковые значения в случае имени базы данных или числа.
Затем можно добавить дополнительные значения для сравнения. В моем примере я фильтрую запросы только для базы данных AdventureWorks, а также запросы, выполняющиеся дольше 1 000 микросекунд. Определение фильтра показано на рис. 3-11.

![[Figure 3-11.png]]

Рисунок 3-11. Множественные критерии фильтрации для Events (События)

Как и в случае с Actions (Действиями), в левой части экрана в поле Selected events (Выбранные события) добавлен флажок, указывающий на применение фильтров к Events (Событиям). Вы также можете увидеть выбор логической операции между "And" и "Or" при определении более чем одного предиката. В данном случае я выбрал "And".  
В нижней части страницы вы также можете увидеть описание Field (Поле), по которому я выполняю фильтрацию, что поможет вам в процессе работы.  
Как и прежде, максимизация этого окна позволяет увеличить размер колонок, делая их более читаемыми. Это хорошая привычка, которую следует взять на вооружение при создании сеансов Extended Events (Расширенные события).

## Дополнительные Event Fields (Поля события)

Последней вкладкой окна Configuration Event (Конфигурация события) является вкладка Event Fields (Поля события). На этой вкладке можно одновременно выбрать только одно событие. При выборе более одного события вкладка становится пустой. На рис. 3-12 я выбрал событие rpc_completed:

![[Figure 3-12.png]]

Рисунок 3-12. Event Fields (Поля события) для события rpc_completed

Fields(поля) без галочки - это поля, которые всегда будут возвращаться при данном событии. Fields(поля) с галочками - это необязательные поля. По умолчанию rpc_completed включает в себя такие параметры, как duration, object_name и row_count. Однако statement является необязательным, хотя и выбран по умолчанию. Вы можете отключить его, чтобы уменьшить затраты на перехват этого события, но при этом вы отказываетесь от возможности видеть значения параметров вызова процедуры. При необходимости можно включить опциональные поля output_parameters или data_stream. Не все события предусматривают опциональные поля, но многие - да, поэтому при настройке собственных событий стоит обратить внимание на эту область.  
После того как все эти значения установлены, остается определить, куда будут направляться выходные данные, полученные в результате перехвата событий.

## Определение целей  
  
По умолчанию целевой объект определять не нужно. При создании сеанса вывод может осуществляться в область памяти, называемую Ring Buffers. Однако это фактически отнимает память у операционной системы и SQL Server, поэтому в производственных средах или для некоторых тестов в непроизводственных средах использовать Ring Buffers не стоит. Вместо этого вы получаете несколько вариантов. Страница Data Storage (Хранилище данных), или Targets (Цели), по умолчанию выглядит так, как показано на рис. 3-13.

![[Figure 3-13.png]]

Рисунок 3-13. Страница Data Storage (Хранилище данных) или Targets (Цели)

Для начала работы в окне появится надпись: Click here to add a target ("Нажмите здесь, чтобы добавить цель"). Опции для целей следующие:

- etw_classic_sync_target: Вывод трассировки событий для Windows (ETW). Эта опция используется редко, но при необходимости она доступна.
- event_counter: Подсчет количества повторений события. Простой способ просто отследить, как часто событие происходит в системе, за которой ведется наблюдение.
- event_file: Выводит все захваченные события в файл. Это наиболее часто используемый механизм захвата.
- Гистограмма: Эта цель позволяет определить Event (событие), а затем Action (действие) или Field (поле) для группировки подсчетов. Это чрезвычайно полезно.
- pair_matching: Вы можете определить механизм для сопоставления пар событий. Это сложно использовать и не так удобно, как Causality Tracking("Отслеживание причинности").
- ring_buffer: Область памяти по умолчанию, о которой уже говорилось. Опять же, его не следует использовать в производственной среде.
 
Для каждого конкретного сеанса можно определить одну или несколько таких областей. Я собираюсь объяснить, как использовать цель event_file и цель histogram. Остальные цели, хотя и полезны в конкретной ситуации, не применимы для стандартного мониторинга производительности запросов и их поведения.

## Использование цели event_file Target

Когда вы выбираете event_file Target, экран Data Storage изменяется так, как показано на рис. 3-14.

![[Figure 3-14.png]]

Рисунок 3-14. Выбор цели event_file

Необходимо указать имя файла и путь для вывода Events("События"). Если вы используете Azure SQL Database, то в качестве выходного файла должно использоваться хранилище Amazon, а также необходимо убедиться, что в настройках безопасности разрешен вывод данных с экземпляров Azure SQL Database. Определив имя файла и хранилище, можно выбрать размер файла - в гигабайтах или мегабайтах. По умолчанию используется 1 ГБ, но для некоторых систем этого может быть мало. Однако не стоит делать слишком большой размер, иначе возникает проблема управления файлами. Как правило, для большинства систем оптимальным является объем от 5 до 20 Гбайт. Можно также определить, разрешено ли переносить файлы. Это означает, что при заполнении одного файла открывается другой, и так продолжается до тех пор, пока не будет достигнуто заданное вами Maximum number of files ("Максимальное количество файлов"). После этого Events снова начнет запись в первый файл.  
В целом это наилучший подход для управления данными, собираемыми Extended Events (Расширенными событиями). Вывод в файл создает наименьшую нагрузку на систему. Наличие файлов позволяет сохранить эти данные при необходимости и всегда открыть их в окне Live Data Explorer (см. далее в главе).

## Использование гистограммы Target

Гистограмма Target чрезвычайно полезна. Это удобный способ просто подсчитать количество повторений данного события, но с группировкой информации по полям или действиям. На рис. 3-15 показано, как можно настроить гистограмму для подсчета количества вызовов различных хранимых процедур.

![[Figure 3-15.png]]

Рисунок 3-15. Подсчет всех случаев обращения к хранимым процедурам с помощью гистограммы Target

Я добавил ее в качестве второй Target (Цели), чтобы показать, как это работает.  
При настройке гистограммы Target сначала нужно выбрать из выпадающего списка событие, которое будет использоваться. В него войдут все события, которые вы определили на странице Events. Затем с помощью двух переключателей можно выбрать Action (действие) или Field (поле) из этого события. Я выбрал object_name из события rpc_completed. Это означает, что для каждой отдельной хранимой процедуры будет получен счетчик случаев вызова этой хранимой процедуры. Наконец, задается количество элементов, определяющих гистограмму. По умолчанию это значение равно 256, но при необходимости его можно изменять в большую или меньшую сторону. Большее число создает большую нагрузку на систему, поэтому будьте осторожны при определении этого значения.

## Работа с Sessions (Сессиями)

После создания Session (Сессии) она сохраняется на сервере, к которому была подключена. Вы можете увидеть имеющиеся у вас сессии, используя окно Object Explorer в Management Studio или запросив системные таблицы. На рис. 3-16 показаны сеансы, находящиеся в данный момент на моей машине.

![[Figure 3-16.png]]

Рисунок 3-16. Extended Events (Расширенные сеансы событий) в окне Object Explorer (Обозреватель объектов)

Определить, какие сеансы запущены, а какие остановлены, можно по зеленой стрелке или красному квадрату на символе рядом с сеансом. Отсюда можно остановить или запустить сеанс, отредактировать остановленный сеанс, просмотреть свойства запущенных сеансов или удалить сеансы. Для получения меню достаточно щелкнуть правой кнопкой мыши.  
Управлять сеансами можно также с помощью языка T-SQL, о чем будет рассказано далее в этой главе.  

## Добавление функции Causality Tracking (Отслеживание причинно-следственных связей)  
  
Causality Tracking - это мощная функция в Extended Events. Она позволяет легко определить события, которые связаны друг с другом. Кроме того, она показывает точную последовательность, в которой происходят эти события. Это делает функцию Causality Tracking чрезвычайно полезной в таких ситуациях, как диагностика перекомпиляций. Вы можете фиксировать метрики запроса, а также события перекомпиляции и затем напрямую связывать их друг с другом.  
Causality Tracking задается на уровне сеанса. При включении функции Causality Tracking к захвату Extended Events добавляются дополнительная нагрузка. Я часто использую эту функцию, но при этом стараюсь осторожно подходить к вопросу о том, какую дополнительную нагрузку я оказываю на систему.  
Как показано на рисунке 3-17, к перехваченным Events(Событиям) добавляются дополнительные данные.

![[Figure 3-17.png]]

Рисунок 3-17. Поля Causality Tracking, добавленные к результатам событий

Поля attach_activity_id.guid и attach_activity_id.seq добавляются к событиям вместе с другими полями. Затем можно группировать данные по guid и сортировать их по seq, или по порядку, чтобы получить уникальные наборы данных. Мы будем использовать этот метод в различных главах книги.

## Сценарии для Extended Events(Расширенные события)  
  
Хотя графический интерфейс предоставляет простой способ настройки и управления сессиями Extended Events, можно также использовать T-SQL. T-SQL - это отличный способ перемещения Sessions между серверами. Вы можете написать T-SQL самостоятельно или выполнить сценарий для существующего сеанса из Management Studio. В листинге 3-3 показан пример оператора для создания Session.  
  
```sql
CREATE EVENT SESSION [QueryPerformanceMetrics]
ON SERVER

ADD EVENT sqlserver.rpc_completed
(SET collect_statement = (1)
WHERE ([sqlserver].[database_name] = N'Adventureworks')),

ADD EVENT sqlserver.sql_batch_completed
(WHERE ([sqlserver].[database_name] = N'Adventureworks'))

ADD TARGET package0.event_file
(SET filename = N'QueryPerformanceMetrics', max_file_size = (2048));
```

Листинг 3-3. T-SQL для создания сеанса расширенных событий

Синтаксис относительно прост. Вам необходимо знать, какие Events вы хотите добавить и какие дополнительные Fields они могут иметь (вы можете видеть поле collect_statement в листинге 3-3). Предикаты отображаются в виде операторов WHERE.  
Вы можете определять и контролировать Target (Цели). Короче говоря, с помощью языка T-SQL можно сделать все для настройки сеанса. С помощью T-SQL можно также запускать, останавливать или прекращать сеанс. В листинге 3-4 показаны сценарии для запуска и остановки сессии QueryPerformanceMetrics:

```sql
ALTER EVENT SESSION QueryPerformanceMetrics
ON SERVER

STATE = START;

ALTER EVENT SESSION QueryPerformanceMetrics
ON SERVER

STATE = STOP;
```

Листинг 3-4. Остановка и запуск сессии с помощью T-SQL

Наконец, можно прочитать вывод Extended Events через T-SQL с помощью системной функции. 
В листинге 3-5 приведен пример, показывающий, как это работает: 

```sql
SELECT  fx.object_name,
		fx.file_name,
		fx.event_data
FROM sys.fn_xe_file_target_read_file('.\QueryPerformanceMetrics_*.xel',NULL,NULL,NULL) AS fx;
```

Листинг 3-5. Запрос данных расширенного события напрямую

Результаты запроса показаны на рисунке 3-18.

![[Figure 3-18.png]]

Рисунок 3-18. Результат прямого запроса данных Extended Event

В столбце object_name видно, что эта сессия фиксирует как rpc_completed, так и sql_batch_completed сессии. Видно, что файл сессии хранится в контейнере Linux, в котором работает SQL Server. Наконец, event_data - это XML, содержащий всю информацию, захваченную каждым событием. В последующих главах мы рассмотрим примеры использования данного функционала для поиска и устранения неисправностей.

## Окно Live Data Explorer  
  
Поскольку выходные данные Extended Events представляют собой XML-файл, чтение информации может быть затруднено. Хотя для решения этой проблемы можно написать XQuery на языке T-SQL, что тоже непросто. Вместо этого, насколько это возможно, я буду опираться на окно Live Data Explorer для работы с выходными данными Extended Events.  
В окно Live Data Explorer можно попасть либо открыв файл Extended Events, либо щелкнув правой кнопкой мыши на запущенном сеансе и выбрав в контекстном меню пункт "Watch Live Data". В любом случае при первом открытии окна и начале захвата событий оно будет выглядеть так, как показано на рис. 3-19.

![[Figure 3-19.png]]

Рисунок 3-19. Первичный вид окна Live Data

Экран разделен на две части. В верхней части отображается ряд зафиксированных событий. В нижней части находятся все поля данного события. Выбрав событие в верхней части экрана, можно увидеть его детали в нижней части. Хотя окно Live Data можно использовать и таким образом, это неэффективно.  
Чтобы эффективно использовать окно Live Data, необходимо изменить структуру таблицы в верхней части экрана. Можно щелкнуть правой кнопкой мыши на поле и выбрать из контекстного меню пункт "Показать столбец в таблице". Я сделал это и добавил duration в свою сетку на рис. 3-20. 

![[Figure 3-20.png]]


Рисунок 3-20. Добавление полей в таблицу для удобства просмотра

Теперь вы можете увидеть, насколько полезным может быть такой способ использования информации. Кроме того, можно воспользоваться всеми инструментами, доступными в Live Data Explorer. В верхней части экрана должна быть панель инструментов, как показано на рис. 3-21.

![[Figure 3-21.png]]

Рисунок 3-21. Панель инструментов Live Data Explorer

Справа расположена кнопка "Choose Columns...". При нажатии на нее открывается новое окно, в котором можно выбрать нужные колонки, как показано на рис. 3-22.

![[Figure 3-22.png]]

Рисунок 3-22. Окно Choose Columns в проводнике Live Data Explorer

Я указал столбцы, которые хочу видеть, и упорядочил их с помощью элементов управления на экране. Стрелки влево/вправо позволяют добавлять или удалять поля. Стрелки вверх/вниз справа служат для управления порядком. Наконец, я использовал функцию "Объединенные столбцы" для создания столбца, обозначенного выше как "[QueryText]", чтобы объединить поля statement и batch_ text в один столбец таблицы. Результаты показаны на рис. 3-23.

![[Figure 3-23.png]]

Рисунок 3-23. Новая таблица с выделенными столбцами на экране

Теперь в таблице можно увидеть гораздо больше информации и она стала гораздо удобнее для навигации и поиска нужной информации. Теперь я могу еще больше повысить контроль над информацией.  
Если вы снова посмотрите на панель инструментов, как показано на рис. 3-21, слева вы увидите красную рамку или квадрат. Если навести на него курсор мыши, то появится всплывающая подсказка с надписью "Stop the data feed". Таким образом можно приостановить сбор данных в Live Data Explorer. Это никак не влияет на сеанс расширенных событий. Затрагивается только информация на экране. Нажатие на эту кнопку включает ряд других кнопок на панели инструментов. Если вы просматриваете файл, по которому не ведется активный сбор данных, то красное квадратик будет отключен, а остальные кнопки уже будут включены.  
Мы не будем подробно останавливаться на всех аспектах работы программы Live Data Explorer, но остановимся на нескольких ключевых моментах. Во-первых, при приостановленном просмотре данных можно добавлять или удалять закладки, что облегчает поиск нужных событий. Кроме того, можно сортировать события, щелкнув на столбце таблицы. Также можно искать события с помощью кнопки поиска, которая открывает новое окно, как показано на рис. 3-24.

![[Figure 3-24.png]]

Рисунок 3-24. Использование функции поиска в программе Live Data Explorer

Кроме того, можно сохранить настройки отображения в файле и поделиться ими с другими членами команды. Вы также обнаружите, что после перестановки столбцов в сеансе ваш экземпляр Management Studio всегда будет открывать этот сеанс в той конфигурации, в которой вы его оставили.  
Существуют две дополнительные функции, которые мы рассмотрим более подробно.  
  
## Filtering Live Data (Фильтрация данных в реальном времени)  
  
Функция поиска, показанная на рис. 3-24, позволяет находить информацию в окне Live Data Explorer. Однако можно также напрямую фильтровать информацию, чтобы отображались только определенные данные. Нажав на кнопку Filters на панели инструментов, можно открыть окно Filter. Я задал несколько параметров, как показано на рис. 3-25.

![[Figure 3-25.png]]

Рисунок 3-25. Окно фильтра Live Data с различными установками фильтров

Фильтр может использовать как временные, так и поисковые критерии. В примере, приведенном на рис. 3-25, я ограничил временной интервал примерно 30-минутным окном. Я также добавил фильтр по длительности, чтобы возвращать только значения, превышающие 1000 микросекунд.  
После установки фильтра данные, отображаемые в окне Live Data Explorer, ограничиваются только теми, которые соответствуют заданным критериям. Фильтры можно также очистить.  

## Агрегирование живых данных  
  
В книге я постоянно использую возможности Live Data Explorer для агрегирования данных. Когда вы видите фразу "в среднем этот запрос выполняется за X времени", это означает, что я воспользовался этим механизмом. Чтобы воспользоваться этим преимуществом, необходимо использовать два разных окна. Первое - это кнопка Группировка. При нажатии на нее на панели инструментов открывается окно, показанное на рис. 3-26.  
  
![[Figure 3-26.png]]

Рисунок 3-26. Окно группировки Live Data Explorer

Я выбрал один из столбцов, по которому хочу сгруппировать данные, в данном случае искусственный столбец [Query Text]. Таблица в окне Live Data Explorer немедленно обновится. Она группируется на основе выбранного столбца или столбцов, как показано на рис. 3-27.

![[Figure 3-27.png]]

Рисунок 3-27. Таблица Explorer Live Data, сгруппированная по столбцу

Видно, что поскольку мы используем оператор для хранимых процедур, то каждое значение параметра означает отдельную строку. И все же в одной нашей выборке имеется 36 отдельных экземпляров. Я показал это в развернутом виде, чтобы вы могли видеть, что выбранные вами столбцы все еще видны.  
Если бы я хотел сгруппировать хранимые процедуры, мне пришлось бы добавить в таблицу object_name и затем группировать по нему, а не по [QueryText], как я сделал ранее. Группировать можно только по тем столбцам, которые видны в таблице.  
После внесения этих изменений щелкнем на кнопке Агрегирование. Откроется еще одно окно. В этом окне я заполнил несколько примеров, как показано на рис. 3-28.

![[Figure 3-28.png]]

Рисунок 3-28. Настройка агрегации для Live Data Explorer

На выбор предлагаются различные варианты агрегации:

- Минимум
- Максимум
- Среднее
- Сумма
- Подсчет

После того как я задал агрегирование и нажал кнопку OK, моя таблица снова изменилась, как показано на рис. 3-29.

![[Figure 3-29.png]]

Рисунок 3-29. Таблица Live Data Explorer, показывающая агрегированные данные

Теперь на основании 41 выполнения процедуры exec `sp_executesql N'SELECT TOP 1` я могу сказать, что в среднем она выполняется за 704216316,219512 микросекунд. Также видно, что максимальное значение logical_reads составило 474174457, а минимальное cpu_time - 355078000.  
Здесь можно увидеть, как много полезного дает Live Data Explorer. Это очень удобный способ быстрого измерения и понимания производительности запросов.

## Общие рекомендации по использованию Extended Events  
  
Хотя Extended Events - это замечательный инструмент, оказывающий минимальное воздействие на экземпляры SQL Server, ничто не может быть полностью бесплатным. Я могу дать несколько рекомендаций, чтобы использование Extended Events было более успешным:  
  
- Устанавливайте максимальный размер файла должным образом.  
- Избегайте отладочных событий.  
- Избегайте использования No_Event_Loss.  
  
Более подробно я расскажу об этом в следующих разделах.  
И еще одно небольшое замечание не требующее подробного описания. Для использования облегченной статистики (более подробно рассматривается в главе 4), если вы используете SQL Server 2014, вам необходимо создать сеанс Extended Events с событием query_thread_profile.

## Установите максимальный размер файла оптимальным образом  
  
По умолчанию для файлов установлено значение 1 ГБ. Это очень мало, если учесть объем информации, который можно собрать с помощью Extended Events. Чтобы обеспечить достаточное пространство для сбора информации и не ждать, пока файловая подсистема создаст для вас файлы, пока заполнится буфер, лучше установить это число гораздо выше, где-то в диапазоне от 5 до 20 ГБ. В противном случае это может привести к потере событий. Но это зависит от вашей системы. Если вы хорошо представляете себе уровень выходных данных, установите размер файла, более соответствующий вашей рабочей среде.

## Избегайте отладочных событий  
  
Extended Events не только предоставляет механизм наблюдения за поведением SQL Server и его внутренним устройством, значительно превосходящий возможности трассировки событий, но и используется компанией Microsoft для устранения неисправностей SQL Server. Ряд событий связан с отладкой SQL Server. По умолчанию они недоступны через мастер, но вы имеете доступ к ним через команду T-SQL и есть возможность включить их через выбор канала в окне редактора сессий.  
Без прямых указаний Microsoft не используйте их. Они могут быть изменены и предназначены только для внутреннего использования Microsoft. Если вы все же решили поэкспериментировать, то следует обратить особое внимание на события, включающие в себя "break action". Это означает, что если событие сработает, то оно остановит SQL Server именно на той строке кода, которая вызвала это событие. Это означает, что ваш сервер будет полностью отключен от сети и окажется в неизвестном состоянии. Это может привести к серьезному сбою в работе производственной системы. Это может привести к потере данных и повреждению базы данных.

## Избегайте использования No_Event_Loss  
  
Extended Events устроены таким образом, что некоторые события будут теряться. Это вполне вероятно и так задумано. Однако при настройке сеанса можно использовать параметр No_Event_Loss. Если сделать это на системах, уже находящихся в состоянии нагрузки, то может возникнуть значительная дополнительная нагрузка на систему, поскольку вы фактически говорите ей сохранять информацию в буфере независимо от последствий. Для небольших и целенаправленных сессий, нацеленных на определенное поведение, такой подход может быть приемлемым.

## Резюме  
  
В этой главе мы рассмотрели три лучших способа сбора метрик запросов. Вы можете использовать агрегированные данные из кэша через DMV. Можно хранить данные вместе с базами данных в Query Store. С помощью Extended Events можно получить чрезвычайно подробные данные о поведении запросов. Вы будете комбинировать и сочетать их по мере того, как будете отслеживать свои собственные показатели производительности запросов.  
В следующей главе мы начнем использовать планы выполнения (Execution Plans) для понимания поведения запросов в SQL Server.