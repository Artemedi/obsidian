### Методы измерения производительности запросов  

Для того чтобы понять, на каких запросах следует сосредоточиться при их настройке, нам необходим метод точного измерения производительности запросов. Кроме того, по мере того как мы будем предпринимать различные попытки улучшить производительность запросов, нам необходимо уметь фиксировать метрики, которые позволят нам понять, насколько хорошо работают наши улучшения и работают ли они вообще. И, наконец, нам нужно уметь измерять результаты наших улучшений, чтобы подтвердить их эффективность и начать процесс заново, выявляя следующий плохо работающий запрос. Несмотря на то, что существует большое количество механизмов для определения производительности запросов, мы сосредоточим наши усилия на трех, которые, по моему мнению, являются наиболее точными и простыми в реализации.  
Хотя остальные механизмы тоже работают, я считаю, что эти три работают лучше всего. Если вы решите использовать другой механизм, просто будьте последовательны в том, что вы измеряете, потому что каждый инструмент сбора метрик, который я использовал, отличается от всех остальных.  
В этой главе мы узнаем о следующем  
  
- Использование динамических представлений управления  
- Сбор подробных метрик с помощью расширенных событий  
- Метрики производительности запросов в хранилище запросов  
#queryperformance

## Методы сбора метрик производительности запросов  
  
Существует большое количество способов сбора метрик запросов. Большинство из них одинаково точны, но некоторые либо проще в использовании, либо дают более полную информацию, либо лучше работают в масштабе больших систем. Позвольте мне пробежаться по всем возможным вариантам, а затем мы кратко обсудим, почему я не использую одни показатели так же часто, как другие. Ниже перечислены возможные методы измерения производительности запросов:  
  
- Включение статистики клиента  
- Свойства соединения  
- SET STATISTICS TIME/IO  
- QueryTimeStats в плане выполнения  
- Хранилище запросов  
- Представления динамического управления (DMVs)  
- События трассировки (Profiler)  
- Расширенные события  
  
Поскольку о DMVs, Query Store и Extended Events мы будем говорить в оставшейся части главы, я хочу рассказать об остальном прямо здесь. Начнем с единственного показателя, который на самом деле не является точным (в отличие от всех остальных), - Include Client Statistics.  
  
## Включить статистику клиентов 

Для этого нужно щелкнуть правой кнопкой мыши в окне запроса в SQL Server Management Studio (SSMS) и выбрать из контекстного меню пункт "Include Client Statistics". При этом будет фиксироваться время выполнения и ввод-вывод с клиента, на котором выполняется запрос. Это означает, что сетевое время, локальная борьба за ресурсы и все остальное негативно скажется на измерении производительности. Вывод этих значений никак не совпадает с результатами других методов. В связи с этим я просто никогда не использую этот метод.  
#ClientStatistics

## Свойства соединения  
  
Этот метод на самом деле очень удобен, хотя я не использую его в качестве основной меры. Перед выполнением запроса или даже после него щелкните правой кнопкой мыши в окне запроса в SSMS и выберите в контекстном меню пункт "Свойства". В результате откроется окно Properties (которое мы будем часто использовать с планами выполнения на протяжении всей книги; я обычно оставляю это окно открытым и доступным все время работы). В нем вы найдете информацию "Детали соединения". Эта информация включает в себя "Время, прошедшее с момента подключения", которое на самом деле является точным показателем производительности запроса. Хотя в SSMS производительность запроса можно увидеть в нижней части экрана, она измеряется только с точностью до секунды.  
Здесь же значения точны до миллисекунд. Единственная проблема заключается в том, что он не дает нам измерения ввода/вывода, поэтому он не так полезен, как другие измерения, которые дают нам и прошедшее время, и ввод/вывод, и, в некоторых случаях, использование процессора. Однако если вы забудете включить какой-либо другой механизм сбора данных, то этот всегда будет доступен, что, опять же, делает его очень удобным.
#ConnectionProperties
  
## SET STATISTICS TIME/IO  
  
Это классический механизм измерения производительности при настройке запросов. В предыдущих версиях книги эти значения широко использовались. Они точны, поэтому если вы решите их использовать, то все будет в порядке. Их можно использовать, зайдя в Options для SSMS, щелкнув правой кнопкой мыши и выбрав их из контекстного меню, или используя T-SQL для SET STATISTICS TIME ON (что делает этот механизм удобным и в Azure Data Studio).  
Позвольте мне объяснить, почему я больше не использую их. Во-первых, вы получаете только одно измерение. Я обнаружил, что получаю более точные результаты, если выполняю запрос несколько раз, а затем усредняю результаты. Это очень трудно сделать с помощью данного измерения. Вы также не получаете данных об использовании процессора. Наконец, если вы фиксируете TIME и IO с помощью этого метода, то фиксация IO может негативно повлиять на фиксацию TIME, сделав ее менее точной. Обычно это заметно только для запросов, выполняющихся менее секунды или даже менее 100 миллисекунд. Тем не менее, когда точность нужна больше всего, приходится настраиваться на последние несколько миллисекунд. Отсутствие такой точности снижает полезность этого механизма.  
#SETSTATISTICS

## QueryTimeStats в Плане выполнения  
  
При захвате метрик времени выполнения с планом выполнения, который в SSMS, начиная с 2016 года, называется "Фактический план выполнения", вы получаете метрики времени выполнения запроса, включая статистику ожидания. Это точные измерения, которые являются частью плана выполнения. Я обязательно буду их использовать. Однако, опять же, они отображаются только для одного выполнения, что затрудняет получение средних значений. Кроме того, захват планов выполнения негативно сказывается на измерении времени, поскольку захват метрик времени выполнения вместе с планом выполнения замедляет выполнение запроса. По этой причине, когда мне нужны точные показатели производительности, я не беру планы выполнения. Этот простой факт означает, что я не могу полагаться на этот показатель постоянно.  
  
## Трассировка событий (Profiler)  
  
Это может быть болезненной темой. Многие опытные специалисты по работе с данными уже давно работают с Trace Events и Profiler (графический интерфейс пользователя для работы с данными Trace Event). Использование этих инструментов для них комфортно, они приобрели отличные навыки работы с ними и не собираются останавливаться. Я не собираюсь стоять у них на пути. Однако по ряду причин я не буду пропагандировать использование Trace Events, и если вы только начинаете заниматься настройкой производительности запросов, я настоятельно рекомендую не использовать их.  
Во-первых, Trace Events очень дорогостоящая операция для операционной системы SQL Server. В отличие от Extended Events, которые, начиная с SQL Server 2008, были включены непосредственно во внутреннюю модель SQL Server, Trace Events были разработаны и внедрены отдельно. Это приводит к тому, что они занимают больше памяти и процессора, чем Extended Events. 
Из-за того, что Trace Events собирают информацию, их нельзя отфильтровать на этапе захвата, как в случае Extended Events. Это означает, что все необходимые для захвата события ресурсы используются, а затем происходит фильтрация и это событие удаляется из результатов.
Другая проблема связана с графическим интерфейсом Profiler. Если подключить Profiler GUI к Trace Events на рабочем сервере, то он создает на нем дополнительное пространство памяти и использует его для обработки событий в реальном времени, что приводит к сокращению ресурсов системы.
Наконец, использование данных в Trace Events не так эффективно, как это можно сделать с помощью окна Live Data Explorer в Extended Events.
По всем этим причинам на системах с SQL Server 2012 и выше я не буду использовать Trace Events для сбора информации. До 2012 года Trace Events по-прежнему является предпочтительным механизмом.
#profiler

## Представления динамического управления  

Существует очень большое количество DMV. Даже если мы ограничимся рассмотрением DMV, связанных с производительностью запросов, их все равно будет очень много. Поэтому я не буду пытаться описать их все и способы их использования. Вместо этого мы рассмотрим здесь основные DMV, связанные с производительностью запросов, а о дополнительных DMV мы будем говорить на протяжении всей книги (некоторые из них мы представили в главе 2).  
DMV делятся на две большие категории: для запросов, выполняющихся в данный момент, и для запросов, которые были выполнены ранее. Информация, собранная для ранее выполненных запросов, полностью зависит от кэша. Если по какой-либо причине запрос устарел или был принудительно удален из кэша, то все метрики запроса уходят вместе с ним. Кроме того, информация о ранее выполненных запросах является только агрегированной. Вы не сможете отличить запрос, выполненный в 2 часа ночи, от того же запроса, выполненного в 3 часа ночи, если только не воспользуетесь DMV для сбора метрик в оба времени.  
обоих случаях.  
Я часто использую DMV для метрик запросов по нескольким причинам. Во-первых, большинство из них доступны во всех версиях SQL Server, начиная с 2005 года и выше, включая AWS RDS и Azure SQL Database. Это означает, что у меня всегда есть возможность получить метрики производительности запросов. Во-вторых, не всегда на сервере будут постоянно включены другие методы. Некоторые базы данных могут иметь слишком высокую нагрузку для работы Query Store. Хотя Extended Events очень легки, они не бесплатны, поэтому они тоже не будут запущены всегда.  
Тем не менее, я всегда смогу взглянуть на метрики запросов через DMV.  
Давайте сначала рассмотрим, как можно перехватывать активно выполняющиеся запросы. 
#dvm

## Запросы с активным выполнением

Важно воспринимать DMV как строительные блоки или лего. Их можно собирать по-разному. Однако есть несколько отправных точек, к которым вы всегда будете возвращаться. Для запросов, которые находятся в активном выполнении, отправной точкой чаще всего является sys.dm_exec_requests. Этот DMV собирает огромное количество информации об исполняющихся запросах, включая следующие сведения:  
  
- Starttime: Когда запрос начал выполняться  
- Command Type: Какой это тип запроса  
- Plan_handle: Используется для получения плана выполнения из кэша  
- Sql_handle: Используется для получения текста T-SQL из кэша  
- Blocking_session_id: Если процесс заблокирован, то какая сессия его блокирует  
- Wait_type: Если процесс ожидает, то чего он ожидает  
- Total_elapsed_time: Сколько времени выполняется процесс  
- Cpu_time: Сколько процессора было потреблено процессом  
- Reads: Сколько чтений было выполнено этим процессом  
- Writes: Сколько записей было произведено этим процессом.  
  
Существует еще больше полезной информации, но общее представление вы получили.  
Чтобы действительно использовать DMV для получения интересной информации, нам потребуется объединить его с несколькими другими DMV. Первая - sys.dm_exec_query_plan(), которая содержит все планы выполнения, находящиеся в кэше планов. Вторая - sys.dm_exec_sql_text(), которая содержит пакетный текст T-SQL для выполняемого запроса. В листинге 3-1 показан один из возможных способов комбинирования этих DMV для получения полезных метрик запроса для выполняющихся в данный момент запросов.  
  
Листинг 3-1. Комбинирование sys.dm_exec_requests с другими DMV
```sql
SELECT  dest.text,
		deqp.query_plan,
		der.cpu_time,
		der.logical_reads,
		der.writes
FROM sys.dm_exec_requests AS der
	CROSS APPLY sys.dm_exec_query_plan(der.plan_handle) AS deqp
	CROSS APPLY sys.dm_exec_sql_text(der.plan_handle) AS dest;
```

Вы можете использовать гораздо более сложные запросы к этим DMV, например возвращать отдельные данные, а не целые пакеты, отфильтровывать session_id для самого запроса и многое другое. Однако этого вполне достаточно для начала работы.

## Выполненные ранее запросы  
  
Для просмотра ранее выполненных запросов у нас есть несколько вариантов с чего начать. Наиболее распространенным является использование sys.dm_exec_query_stats. Этот DMV содержит много интересной информации, когда речь идет о метриках производительности запросов:  
  
- Sql_handle: Используется для получения T-SQL для пакета.  
- Plan_handle: Используется для получения плана выполнения запроса  
- Last_execution_time: Время последнего выполнения данного запроса  
- Execution_count: Сколько раз был выполнен запрос  
- Total_logical_reads: Количество логических чтений  
- Last_logical_reads: Количество чтений при последнем выполнении запроса  
- Avg_logical_reads: Среднее число чтений за все запуски запроса.  
  
И, как и прежде, многое другое. Вы можете увидеть общее, среднее, минимальное и максимальное значение по по целому ряду показателей, включая время, процессор, чтение и запись.  
Как и раньше, вы можете комбинировать этот показатель с другими DMV, чтобы получить более полную картину. полную картину. В листинге 3-2 показан один из возможных способов просмотра данных.  
  
Листинг 3-2. Комбинирование sys.dm_exec_query_stats с другими DMV

```sql
SELECT 
	dest.text,
	deqp.query_plan,
	deqs.execution_count,
	deqs.min_logical_writes,
	deqs.max_logical_reads,
	deqs.total_logical_reads,
	deqs.total_elapsed_time,
	deqs.last_elapsed_time
FROM sys.dm_exec_query_stats AS deqs
	CROSS APPLY sys.dm_exec_query_plan(deqs.plan_handle) AS deqp
	CROSS APPLY sys.dm_exec_sql_text(deqs.sql_handle) AS dest;
```

Можно добавить предложение WHERE для поиска определенного текста и многое другое. Существуют также специальные DMV для определенных типов объектов:

- sys.dm_exec_procedure_stats: Работает аналогично sys.dm_exec_query_stats, но только для хранимых процедур  
- sys.dm_exec_function_stats: Та же идея, но для функций, определяемых пользователем  
- sys.dm_exec_trigger_stats: Возвращает агрегированную информацию о производительности триггера  
  
С помощью всех этих DMV можно получить информацию, необходимую для отображения агрегированной производительности запросов, находящихся в кэше. Мы покажем дополнительные примеры запросов с использованием DMV на протяжении всей книги.  

## Query Store

Query Store был представлен в SQL Server 2016 и с тех пор претерпел ряд обновлений в каждом выпуске. Основное поведение не изменилось. Query Store включается для каждой базы данных отдельно. Оно будет собирать метрики запросов в агрегированном виде и хранить их в базе данных, где оно включено. Агрегированные показатели разбиваются по времени; по умолчанию это 60 минут, что позволяет сравнивать производительность во времени, а не просто опираться на агрегированные показатели. Мы подробно рассмотрим Query Store  
в главе 6, поскольку там очень много информации. Тем не менее, я хотел бы затронуть эту тему здесь как один из трех основных методов сбора метрик запросов.  
  
## Extended Events

Впервые расширенные события были представлены в SQL Server 2008, однако в то время они просто не обеспечивали достаточного уровня функциональности, чтобы сделать их полезными для сбора метрик запросов. Однако обновления Extended Events, представленные в SQL Server 2012, включающие графический интерфейс, а также ряд изменений в их поведении и множество новых событий, сделали их не только пригодными для сбора метрик запросов, но и наиболее эффективным способом получения подробной информации о производительности запросов. Trace Events и Profiler по-прежнему работают в SQL Server, но не в Azure SQL Database. Однако, учитывая затраты, которые они вносят в систему, и отсутствие современной функциональности, я не буду использовать их в книге и не рекомендую применять их в системах, работающих под управлением SQL Server 2012 и выше.  

Расширенные события состоят из множества различных программируемых конструкций, однако мы собираемся максимально упростить их использование. В связи с этим мы сосредоточимся на следующем:

- Sessions (Сессии) : Определяют, какие события будут фиксироваться, как они будут храниться, как они будут связаны друг с другом, и все другие аспекты поведения Extended Events.  
- Events (События) : Действия, происходящие в SQL Server, одним из основных направлений которых является производительность запросов, но также включает такие вещи такие как ожидание, перекомпиляция, тупики и т.д.  
- Global Fields ( Actions ): Это дополнительные элементы информации которые могут быть добавлены к определенному событию. Они представляют собой дополнительные функциональную активность в SQL Server, поэтому должны использоваться с умом.  
- Event Fields (Поле событий): Каждое событие состоит из комбинации стандартной и дополнительной информации, которая должна быть записана. Это ключевые данные, которые делают Extended Events очень полезными.  
- Predicates (Предикаты): Проще говоря, это предложение WHERE, которое может быть добавлено к расширенным событиям для фильтрации полученной информации.  
- Targets (Цели): Здесь определяется, где хранятся перехваченные данные. По умолчанию здесь используется Ring Buffers, область памяти в Windows, но в производственной среде это не должно использоваться.  
  
Расширенные события можно создавать, редактировать, запускать, останавливать и удалять с помощью GUI-интерфейса в SQL Server Management Studio, более ограниченного интерфейса в Azure Data Studio или с помощью T-SQL. Большую часть времени в этой главе мы посвятим рассмотрению графического интерфейса, поскольку это самый простой способ начать работу с расширенными событиями. В SSMS даже появился графический интерфейс под названием XEvent Profiler, который эмулирует два наиболее распространенных шаблона из Profiler для сбора информации о запросах. Это быстрый способ сразу же увидеть метрики запросов с помощью Extended Events. Однако в данной книге мы не будем его рассматривать. Мы сосредоточимся на том, чтобы показать вам, как создавать свои собственные пользовательские сеансы. Наконец, существует еще один графический интерфейс, называемый окном Live Data, который позволяет исследовать информацию, полученную с помощью Extended Events.  
#ExtendedEvents

## Создание сеанса расширенных событий  
  
Для создания пользовательского сеанса расширенных событий в SSMS существует два отдельных графических интерфейса: мастер создания нового сеанса и окно нового сеанса. Мастер практически ничего не добавляет к процессу и может скрывать некоторые функциональные возможности, поэтому мы сосредоточимся только на окне New Session. Кроме того, окно New Session так же просто в использовании, как и мастер. Вы также будете использовать окно New Session, когда захотите отредактировать сессию, поэтому нелишним будет ознакомиться с ним поближе.
Чтобы получить доступ к окну New Session, необходимо перейти в Object Explorer. Откройте меню Management, затем Extended Events и, наконец, Sessions, как показано на рис. 3-1. 

![[Figure 3-1.png]]

Рисунок 3-1. Object Explorer, показывающий, где расположены сессии расширенных событий

Если затем щелкнуть правой кнопкой мыши на Sessions, то появится контекстное меню. Выберите пункт "New Session..." и откроется окно New Session, как показано на рис. 3-2.

![[Figure 3-2.png]]

Рисунок 3-2. Окно "Новый сеанс"

Единственное, что здесь нужно заполнить, - это "Session name". Остальные параметры здесь необязательны. Имя сессии может содержать пробелы. Максимальное количество символов - 128, а имя сессии должно быть уникально на сервере. Я стараюсь использовать достаточно подробные имена, чтобы было понятно, какого рода мониторинг выполняет сессия. 
У вас есть выбор - пойти дальше и создать пользовательский сеанс, или воспользоваться шаблонами. Это выпадающее меню с большим выбором различных шаблонов, большинство из которых ориентированы на сбор показателей производительности различными способами. Также есть возможность загрузить сессию из файла. В качестве примера можно привести следующие шаблоны:

- Count Query Locks: Шаблон, использующий целевую гистограмму вместе с хэш-значением запроса для подсчета блокировок в каждом запросе.
- TSQL: Один из шаблонов "Profiler Equivalent". Он фиксирует входы в систему, а также пакетное выполнение и завершение удаленного вызова процедур (RPC). 
- Query Batch Sampling: Шаблон, специфичный для Extended Events, который использует фильтр для захвата метрик запросов только для 20% всех сессий, работающих на сервере.
- Query Detail Tracking: Захватывает всевозможные типы завершения запросов, пакетных запросов и RPC, отфильтровывая при этом системные запросы и системные базы данных.
- Query Wait Statistic (Статистика ожидания запроса): Еще один шаблон, доступный только для Extended Events, в котором фиксируется каждый запуск и завершение запроса, а также все операторы, внутреннее и внешнее ожидание в 20% всех сессий, включая Causality Tracking (подробно описано далее в этой главе). 

Другими словами, у вас есть с чем работать, а можете продолжить и создать свои собственные сеансы и события.
В центре окна, показанного на рис. 3-2, вы можете увидеть некоторые опции доступные для вашей сессии. Вы можете включить или отключить запуск сессии при старте сервера. Также можно немедленно запустить сессию после завершения ее редактирования. Помимо этого, можно сразу же открыть окно Live Data для просмотра результатов сессии. Я часто пользуюсь этой функцией, особенно при первой настройке сессии. В нижней части экрана можно включить или отключить Causality Tracking для сессии. 
После этого можно нажать на левую часть экрана, где написано Events (События), чтобы начать добавлять и настраивать события.

## Добавление и настройка событий

В любой сессии должно быть добавлено хотя бы одно событие. В любой сессии может быть любое количество событий. Однако я рекомендую проявлять осторожность при добавлении событий в сессию. поскольку перегрузка системы событиями может оказать серьезное негативное воздействие на нее. 
Когда вы впервые открываете страницу Events, она должна выглядеть примерно так, как показано на рис. 3-3.

![[Figure 3-3.png]]

Рисунок 3-3. Выбор сеанса для Extended Events

Окно можно максимизировать, чтобы развернуть столбцы и сделать их более удобными для чтения. Оставлю все по умолчанию, чтобы вы увидели примерно то же самое, что вижу я.  
Список событий находится прямо перед вами. По умолчанию в списке отображаются все события, однако прямо на экране у вас есть четыре различных способа отфильтровать события. В верхней части находится поисковое текстовое окно. Оно автоматически выполняет поиск по символам. Например, если я ищу событие rpc_completed, я могу ввести в окно слово "completed", и в результате у меня получится довольно длинный список. Я могу прокрутить его, чтобы найти то, что мне нужно, как показано на рис. 3-4.  

![[Figure 3-4.png]]

Рисунок 3-4. События, отфильтрованные только по слову "completed"

Можно также изменить способ поиска. По умолчанию, как показано в раскрывающемся списке, расположенном непосредственно рядом с текстовым полем, поиск ведется только по "Event names only". С помощью раскрывающегося списка можно выбрать и другие варианты:  
- Event names and descriptions (Названия и описания событий)
- Event fields only (Только поля события)
- All (Все)

В дополнение к текстовому полю поиска можно также фильтровать по категориям, каналам и пакетам. Я обычно оставляю эти параметры без внимания, поскольку могу найти то, что мне нужно, с помощью поисковой строки. Единственное исключение - канал. Существует только четыре канала:

- Admin (Администратор)
- Analytic (Аналитический)
- Debug (Отладка)
- Operational (Операционный)

По умолчанию канал Debug отключен. Это связано с тем, что события в канале Debug могут быть изменены компанией Microsoft без предварительного уведомления. Кроме того, некоторые события в канале Debug являются опасными. Я рекомендую быть крайне осторожным при использовании событий канала Debug. Лучше просто отказаться от использования этого канала. Определив интересующее меня событие, можно щелкнуть на нем, после чего окно изменится и будет выглядеть так, как показано на рис. 3-5.  
  
